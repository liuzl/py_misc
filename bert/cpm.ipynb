{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at mymusise/CPM-Third-Party.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, TFGPT2LMHeadModel\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('mymusise/CPM-Third-Party')\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"mymusise/CPM-Third-Party\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Dump cache file failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zliu/anaconda3/lib/python3.7/site-packages/jieba/__init__.py\", line 154, in initialize\n",
      "    _replace_file(fpath, cache_file)\n",
      "PermissionError: [Errno 1] Operation not permitted: '/tmp/tmp9qtmcep9' -> '/tmp/jieba.cache'\n",
      "Loading model cost 1.862 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "def pre_text(t):\n",
    "    translator = str.maketrans(\" \\n\", \"\\u2582\\u2583\")\n",
    "    seg_list = [x.translate(translator) for x in jieba.cut(t, cut_all=False)]\n",
    "    new_seg = \" \".join(seg_list)\n",
    "    return new_seg\n",
    "\n",
    "texts = [\n",
    "    '今天天气不错',\n",
    "    '天下武功, 唯快不破',\n",
    "]\n",
    "texts = [pre_text(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextGenerationPipeline\n",
    "text_generater = TextGenerationPipeline(model, tokenizer, device=2) # device= set GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(result):\n",
    "    display(result[0]['generated_text'].replace('▂', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'今天天气 不错 , 心情 也 不错 , 就 想着 出去 散散心 , 散散心 , 散散'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'今天天气 不错 , 咱们 到 城外 散散心 吧 , 咱们 去 哪儿 好'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'今天天气 不错 。 我们 走 吧 ! 好开心 呀 这里 的 景色 真是 漂亮 啊 ... 我 又 发现 了 一个 美丽'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'天下 武功 ,  唯快 不破  。          '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'天下 武功 ,  唯快 不破 之理 ,  你 的 境界 太低 ,  只 适合 在 壁上 来'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'天下 武功 ,  唯快 不破 ! 诗词 云水 清且 永 ... ( 英语 译音 对照表 的 中文翻译 是 怎样 一个 思路 呢 ? 为'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for text in texts:\n",
    "    show(text_generater(text, max_length=20 + len(text)))\n",
    "    show(text_generater(text, max_length=20 + len(text), do_sample=True, top_k=10))\n",
    "    show(text_generater(text, max_length=20 + len(text), do_sample=True, top_k=10, repetition_penalty=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TextGenerationPipeline(model, tokenizer, device=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '今天天气 不错 , 心情 也 不错 , 就 想着 出去 散散心 , 散散心 , 散散心 。 ▂ ▂ ▂ ▂ ▂ ▂ ▂ ▂ ▂ ▂'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(texts[0], max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
