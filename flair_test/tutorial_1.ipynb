{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: NLP Base Types\n",
    "This is part 1 of the tutorial, in which we look into some of the base types used in this library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Sentence\n",
    "\n",
    "There are two types of objects that are central to this library, namely the `Sentence` and `Token` objects. A `Sentence` holds a textual sentence and is essentially a list of `Token`.\n",
    "\n",
    "Let's start by making a `Sentence` object for an example sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"The grass is green .\" - 5 Tokens\n"
     ]
    }
   ],
   "source": [
    "# The sentence objects holds a sentence that we may want to embed or tag\n",
    "from flair.data import Sentence\n",
    "\n",
    "# Make a sentence object by passing a whitespace tokenized string\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# Print the object to see what's in there\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The print-out tells us that the sentence consists of 5 tokens. You can access the tokens of a sentence via their token id or with their index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 4 green\n",
      "Token: 4 green\n"
     ]
    }
   ],
   "source": [
    "# using the token id\n",
    "print(sentence.get_token(4))\n",
    "# using the index itself\n",
    "print(sentence[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The\n",
      "Token: 2 grass\n",
      "Token: 3 is\n",
      "Token: 4 green\n",
      "Token: 5 .\n"
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "In some use cases, you might not have your text already tokenized. For this case, we added a simple tokenizer using the lightweight [segtok library](https://pypi.org/project/segtok/).\n",
    "\n",
    "Simply use the `use_tokenizer` flag when instantiating your `Sentence` with an untokenized string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"The grass is green .\" - 5 Tokens\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "# Make a sentence object by passing an untokenized string and the 'use_tokenizer' flag\n",
    "sentence = Sentence('The grass is green.', use_tokenizer=True)\n",
    "\n",
    "# Print the object to see what's in there\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Tags to Tokens\n",
    "\n",
    "A `Token` has fields for linguistic annotation, such as lemmas, part-of-speech tags or named entity tags. You can add a tag by specifying the tag type and the tag value. In this example, we're adding an NER tag of type 'color' to the word 'green'. This means that we've tagged this word as an entity of type color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grass is green <color> .\n"
     ]
    }
   ],
   "source": [
    "# add a tag to a word in the sentence\n",
    "sentence[3].add_tag('ner', 'color')\n",
    "\n",
    "# print the sentence with all tags of this type\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tag is of class Label which next to the value has a score indicating confidence. Print like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Token: 4 green\" is tagged as \"color\" with confidence score \"1.0\"\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Label\n",
    "\n",
    "tag: Label = sentence[3].get_tag('ner')\n",
    "\n",
    "print(f'\"{sentence[3]}\" is tagged as \"{tag.value}\" with confidence score \"{tag.score}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our color tag has a score of 1.0 since we manually added it. If a tag is predicted by our sequence labeler, the score value will indicate classifier confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
